{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiH8eP4I2-5h"
      },
      "source": [
        "Для построения более сложной модели и оптимизации гиперпараметров можно использовать GridSearchCV из sklearn.modelselection. GridSearchCV позволяет задать набор возможных гиперпараметров, которые он затем проверяет методом \"перебора по сетке\" - он обучает модель на каждой комбинации параметров и возвращает ту, на которой модель показала наилучший результат."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVe6Hc551OLi",
        "outputId": "dce42b6b-cd85-47bd-cbb1-f9a78b50f159"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import r2_score\n",
        "from math import sqrt\n",
        "import numpy as np\n",
        "\n",
        "# Загрузим данные\n",
        "df = pd.read_csv('Yulu.csv')\n",
        "\n",
        "# Преобразуем 'datetime' в datetime формат и извлечем отдельные признаки\n",
        "df['datetime'] = pd.to_datetime(df['datetime'])\n",
        "df['year'] = df['datetime'].dt.year\n",
        "df['month'] = df['datetime'].dt.month\n",
        "df['day'] = df['datetime'].dt.day\n",
        "df['hour'] = df['datetime'].dt.hour\n",
        "\n",
        "# Теперь можем удалить 'datetime'\n",
        "df = df.drop(columns=['datetime'])\n",
        "\n",
        "# Извлечем векторы меток и признаков.\n",
        "X = df.drop('count', axis=1)\n",
        "y = df['count']\n",
        "\n",
        "# Разделим данные на тренировочную и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Обучаем базовую модель\n",
        "baseline_model = RandomForestRegressor()\n",
        "baseline_model.fit(X_train,y_train)\n",
        "\n",
        "# Сетка гиперпараметров для настройки\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Настройка модели с помощью GridSearchCV\n",
        "grid_search = GridSearchCV(estimator = RandomForestRegressor(), param_grid = param_grid, cv = 3)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Выводим лучшие параметры\n",
        "print(grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yrc6TLPIKk_J"
      },
      "source": [
        "GridSearchCV выбрал для нас наилучшие значения гиперпараметров для модели RandomForestRegressor:\n",
        "\n",
        "- 'max_depth': None - это говорит о том, что деревья (дерево в случайном лесу) должны расширяться до тех пор, пока все листья не станут \"чистыми\" (то есть, не содержат элементов разных классов) или пока все элементы в листе не будут представлять собой меньше указанного числа образцов (min_samples_split).\n",
        "\n",
        "- 'min_samples_leaf': 1 - минимальное количество элементов в листе дерева. Может быть настроено, чтобы избежать переобучения.\n",
        "\n",
        "- 'min_samples_split': 2 - минимальное количество элементов, которое должно быть в узле, прежде чем он может быть разделен на поддеревья. Может быть также настроено, чтобы бороться с переобучением.\n",
        "\n",
        "- 'n_estimators': 200 - количество деревьев в случайном лесу. На практике чем больше деревьев, которые мы добавляем, тем лучше происходит обобщение модели. Однако это усложняет модель, увеличивает время обучения и не всегда приводит к улучшению, особенно после определенной точки.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TdEYOX5GC1t",
        "outputId": "a74bf47e-6292-491b-b8d6-e97f7c1eb985"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE модели:  3.0169085960703486\n",
            "R2 модели:  0.9997242477304086\n"
          ]
        }
      ],
      "source": [
        "# Используя оптимальные гиперпараметры, обучим новую модель\n",
        "model = RandomForestRegressor(\n",
        "    n_estimators = grid_search.best_params_['n_estimators'],\n",
        "    max_depth = grid_search.best_params_['max_depth'],\n",
        "    min_samples_split = grid_search.best_params_['min_samples_split'],\n",
        "    min_samples_leaf = grid_search.best_params_['min_samples_leaf'])\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Предсказания модели на тестовом наборе\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Вычисляем RMSE\n",
        "rmse_model = sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE модели: \", rmse_model)\n",
        "\n",
        "# Вычисляем R2\n",
        "r2_model = r2_score(y_test, y_pred)\n",
        "print(\"R2 модели: \", r2_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9M-yC5Cm4bZe"
      },
      "source": [
        "На старой модели показатель RMSE был: 3.0471543801299705\n",
        "Значение текущей модели улучшилось, но не критично. ПРедполагается, что это из-за набора данных, которые специально были подготовлены для тренировки. Поэтому  и точность данных примерно одинаковая (ожинаковая, потому что 3 из 1000 - это небольшая ошибка, а уж о долях говорить тут вообще не имеет смысла)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdtBPLl5OYRQ",
        "outputId": "9c5c9744-7dc4-4f65-9748-7220205cf077"
      },
      "outputs": [],
      "source": [
        "!pip install optuna\n",
        "\n",
        "import optuna\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Замените вашу GridSearchCV на эту функцию\n",
        "def objective(trial):\n",
        "    n_estimators = trial.suggest_int('n_estimators', 100, 200)\n",
        "    max_depth = trial.suggest_int('max_depth', 10, 30)\n",
        "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 4)\n",
        "\n",
        "    model = RandomForestRegressor(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        min_samples_leaf=min_samples_leaf,\n",
        "        min_samples_split=min_samples_split,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    return cross_val_score(\n",
        "        model, X_train, y_train, cv=3, scoring='neg_mean_squared_error').mean()\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "trial = study.best_trial\n",
        "\n",
        "# Handle the best_params\n",
        "best_params = trial.params\n",
        "\n",
        "# Используйте best_params для новых значений\n",
        "best_model = RandomForestRegressor(\n",
        "    n_estimators = best_params['n_estimators'],\n",
        "    max_depth = best_params['max_depth'],\n",
        "    min_samples_split = best_params['min_samples_split'],\n",
        "    min_samples_leaf = best_params['min_samples_leaf'],\n",
        "    random_state=42\n",
        ")\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict with the fine-tuned model\n",
        "y_pred_optuna = best_model.predict(X_test)\n",
        "\n",
        "# Выводим результаты\n",
        "rmse_optuna = sqrt(mean_squared_error(y_test, y_pred_optuna))\n",
        "r2_optuna = r2_score(y_test, y_pred_optuna)\n",
        "\n",
        "print(\"RMSE with Optuna: \", rmse_optuna)\n",
        "print(\"R2 with Optuna: \", r2_optuna)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
